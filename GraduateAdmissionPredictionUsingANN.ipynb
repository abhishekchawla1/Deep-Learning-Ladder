{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40c6a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d3896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3d3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fced23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"G:\\datasets\\Admission_Predict_Ver1.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04568abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3af0e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a599f031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551bcbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.             int64\n",
       "GRE Score              int64\n",
       "TOEFL Score            int64\n",
       "University Rating      int64\n",
       "SOP                  float64\n",
       "LOR                  float64\n",
       "CGPA                 float64\n",
       "Research               int64\n",
       "Chance of Admit      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05c3289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce5082f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>316.472000</td>\n",
       "      <td>107.192000</td>\n",
       "      <td>3.114000</td>\n",
       "      <td>3.374000</td>\n",
       "      <td>3.48400</td>\n",
       "      <td>8.576440</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.72174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "      <td>11.295148</td>\n",
       "      <td>6.081868</td>\n",
       "      <td>1.143512</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.92545</td>\n",
       "      <td>0.604813</td>\n",
       "      <td>0.496884</td>\n",
       "      <td>0.14114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.750000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.127500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.250000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
       "count  500.000000  500.000000   500.000000         500.000000  500.000000   \n",
       "mean   250.500000  316.472000   107.192000           3.114000    3.374000   \n",
       "std    144.481833   11.295148     6.081868           1.143512    0.991004   \n",
       "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
       "25%    125.750000  308.000000   103.000000           2.000000    2.500000   \n",
       "50%    250.500000  317.000000   107.000000           3.000000    3.500000   \n",
       "75%    375.250000  325.000000   112.000000           4.000000    4.000000   \n",
       "max    500.000000  340.000000   120.000000           5.000000    5.000000   \n",
       "\n",
       "            LOR         CGPA    Research  Chance of Admit   \n",
       "count  500.00000  500.000000  500.000000         500.00000  \n",
       "mean     3.48400    8.576440    0.560000           0.72174  \n",
       "std      0.92545    0.604813    0.496884           0.14114  \n",
       "min      1.00000    6.800000    0.000000           0.34000  \n",
       "25%      3.00000    8.127500    0.000000           0.63000  \n",
       "50%      3.50000    8.560000    1.000000           0.72000  \n",
       "75%      4.00000    9.040000    1.000000           0.82000  \n",
       "max      5.00000    9.920000    1.000000           0.97000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8553ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns='Serial No.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e0798bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea405f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "115e03ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "495        332          108                  5  4.5   4.0  9.02         1   \n",
       "496        337          117                  5  5.0   5.0  9.87         1   \n",
       "497        330          120                  5  4.5   5.0  9.56         1   \n",
       "498        312          103                  4  4.0   5.0  8.43         0   \n",
       "499        327          113                  4  4.5   4.5  9.04         0   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "495              0.87  \n",
       "496              0.96  \n",
       "497              0.93  \n",
       "498              0.73  \n",
       "499              0.84  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a55436d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73f0a61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "725db551",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8da9037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99502a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfb833cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c85fe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4b01526",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled=m.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80af5b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96      , 0.89285714, 0.75      , ..., 0.875     , 0.8525641 ,\n",
       "        1.        ],\n",
       "       [0.58      , 0.64285714, 0.5       , ..., 0.375     , 0.63782051,\n",
       "        0.        ],\n",
       "       [0.92      , 0.71428571, 1.        , ..., 1.        , 0.94871795,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.        , 0.42857143, 0.75      , ..., 0.375     , 0.21153846,\n",
       "        0.        ],\n",
       "       [0.98      , 0.96428571, 1.        , ..., 0.75      , 0.92948718,\n",
       "        0.        ],\n",
       "       [0.64      , 0.64285714, 0.75      , ..., 1.        , 0.74679487,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a33dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled=m.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b1643b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56      , 0.5       , 0.25      , 0.75      , 0.75      ,\n",
       "        0.35897436, 1.        ],\n",
       "       [0.62      , 0.78571429, 0.75      , 0.75      , 1.        ,\n",
       "        0.74358974, 0.        ],\n",
       "       [0.62      , 0.67857143, 0.5       , 0.375     , 0.5       ,\n",
       "        0.67307692, 1.        ],\n",
       "       [0.76      , 0.85714286, 1.        , 0.875     , 1.        ,\n",
       "        0.73076923, 1.        ],\n",
       "       [0.22      , 0.35714286, 0.5       , 0.375     , 0.25      ,\n",
       "        0.42628205, 1.        ],\n",
       "       [0.48      , 0.46428571, 0.5       , 0.625     , 0.375     ,\n",
       "        0.48076923, 0.        ],\n",
       "       [0.16      , 0.32142857, 0.25      , 0.125     , 0.25      ,\n",
       "        0.33974359, 0.        ],\n",
       "       [0.24      , 0.64285714, 0.5       , 0.75      , 0.875     ,\n",
       "        0.54487179, 0.        ],\n",
       "       [0.14      , 0.28571429, 0.        , 0.125     , 0.25      ,\n",
       "        0.3525641 , 0.        ],\n",
       "       [0.68      , 0.46428571, 0.5       , 0.5       , 0.75      ,\n",
       "        0.625     , 0.        ],\n",
       "       [0.54      , 0.39285714, 0.25      , 0.375     , 0.25      ,\n",
       "        0.43269231, 0.        ],\n",
       "       [0.6       , 0.42857143, 0.5       , 0.5       , 0.375     ,\n",
       "        0.56730769, 1.        ],\n",
       "       [0.48      , 0.35714286, 0.25      , 0.25      , 0.375     ,\n",
       "        0.46153846, 0.        ],\n",
       "       [0.46      , 0.60714286, 0.5       , 0.75      , 0.625     ,\n",
       "        0.70512821, 0.        ],\n",
       "       [0.88      , 0.89285714, 1.        , 0.75      , 0.875     ,\n",
       "        0.7275641 , 1.        ],\n",
       "       [0.14      , 0.14285714, 0.25      , 0.375     , 0.125     ,\n",
       "        0.34935897, 0.        ],\n",
       "       [0.66      , 0.64285714, 0.75      , 0.75      , 1.        ,\n",
       "        0.66666667, 1.        ],\n",
       "       [0.54      , 0.5       , 0.25      , 0.25      , 0.625     ,\n",
       "        0.42307692, 0.        ],\n",
       "       [0.72      , 0.57142857, 0.5       , 0.5       , 0.625     ,\n",
       "        0.66987179, 0.        ],\n",
       "       [0.2       , 0.46428571, 0.        , 0.        , 0.25      ,\n",
       "        0.32051282, 0.        ],\n",
       "       [0.1       , 0.25      , 0.25      , 0.375     , 0.5       ,\n",
       "        0.2724359 , 0.        ],\n",
       "       [0.6       , 0.42857143, 0.5       , 0.625     , 0.875     ,\n",
       "        0.49358974, 1.        ],\n",
       "       [0.12      , 0.32142857, 0.        , 0.375     , 0.5       ,\n",
       "        0.28205128, 0.        ],\n",
       "       [0.82      , 0.85714286, 1.        , 1.        , 1.        ,\n",
       "        0.82692308, 1.        ],\n",
       "       [0.64      , 0.64285714, 1.        , 1.        , 0.75      ,\n",
       "        0.73717949, 1.        ],\n",
       "       [0.56      , 0.64285714, 0.        , 0.375     , 0.625     ,\n",
       "        0.55769231, 1.        ],\n",
       "       [0.7       , 0.78571429, 0.75      , 0.5       , 0.25      ,\n",
       "        0.51282051, 0.        ],\n",
       "       [0.42      , 0.21428571, 0.        , 0.        , 0.375     ,\n",
       "        0.21153846, 0.        ],\n",
       "       [0.32      , 0.28571429, 0.25      , 0.5       , 0.5       ,\n",
       "        0.38461538, 0.        ],\n",
       "       [0.28      , 0.28571429, 0.25      , 0.375     , 0.625     ,\n",
       "        0.40705128, 0.        ],\n",
       "       [0.52      , 0.39285714, 0.25      , 0.25      , 0.875     ,\n",
       "        0.62179487, 0.        ],\n",
       "       [0.12      , 0.25      , 0.25      , 0.5       , 0.625     ,\n",
       "        0.15384615, 0.        ],\n",
       "       [0.22      , 0.5       , 0.75      , 0.375     , 0.5       ,\n",
       "        0.53525641, 0.        ],\n",
       "       [0.66      , 0.64285714, 1.        , 0.75      , 1.        ,\n",
       "        0.69871795, 1.        ],\n",
       "       [0.5       , 0.46428571, 0.25      , 0.25      , 0.375     ,\n",
       "        0.2724359 , 0.        ],\n",
       "       [0.16      , 0.32142857, 0.75      , 0.375     , 0.875     ,\n",
       "        0.28525641, 1.        ],\n",
       "       [0.76      , 0.57142857, 0.75      , 0.875     , 0.75      ,\n",
       "        0.76282051, 1.        ],\n",
       "       [0.68      , 0.75      , 0.75      , 0.875     , 0.875     ,\n",
       "        0.78525641, 1.        ],\n",
       "       [0.2       , 0.35714286, 0.5       , 0.625     , 0.375     ,\n",
       "        0.43910256, 0.        ],\n",
       "       [0.4       , 0.42857143, 0.5       , 0.25      , 0.625     ,\n",
       "        0.50320513, 0.        ],\n",
       "       [0.48      , 0.53571429, 0.25      , 0.375     , 0.75      ,\n",
       "        0.47115385, 0.        ],\n",
       "       [0.78      , 0.78571429, 1.        , 0.75      , 1.        ,\n",
       "        0.80128205, 1.        ],\n",
       "       [0.8       , 0.85714286, 0.75      , 0.75      , 0.625     ,\n",
       "        0.77884615, 1.        ],\n",
       "       [0.52      , 0.64285714, 0.5       , 0.625     , 0.75      ,\n",
       "        0.56410256, 0.        ],\n",
       "       [0.74      , 0.71428571, 0.5       , 0.5       , 0.5       ,\n",
       "        0.61538462, 1.        ],\n",
       "       [0.68      , 0.53571429, 0.75      , 0.75      , 0.875     ,\n",
       "        0.66346154, 1.        ],\n",
       "       [0.86      , 0.96428571, 1.        , 1.        , 0.875     ,\n",
       "        0.95512821, 1.        ],\n",
       "       [0.72      , 0.85714286, 0.5       , 0.625     , 0.75      ,\n",
       "        0.75      , 1.        ],\n",
       "       [0.38      , 0.67857143, 0.25      , 0.375     , 0.75      ,\n",
       "        0.39423077, 0.        ],\n",
       "       [0.48      , 0.5       , 0.25      , 0.75      , 0.625     ,\n",
       "        0.46474359, 0.        ],\n",
       "       [0.32      , 0.39285714, 0.25      , 0.375     , 0.5       ,\n",
       "        0.5       , 0.        ],\n",
       "       [0.44      , 0.32142857, 0.25      , 0.375     , 0.625     ,\n",
       "        0.3974359 , 1.        ],\n",
       "       [0.3       , 0.39285714, 0.25      , 0.375     , 0.625     ,\n",
       "        0.42628205, 0.        ],\n",
       "       [0.7       , 0.71428571, 0.25      , 0.5       , 0.625     ,\n",
       "        0.69230769, 1.        ],\n",
       "       [0.38      , 0.46428571, 1.        , 0.625     , 0.625     ,\n",
       "        0.56410256, 0.        ],\n",
       "       [0.76      , 0.71428571, 0.75      , 0.75      , 0.875     ,\n",
       "        0.73717949, 1.        ],\n",
       "       [0.1       , 0.32142857, 0.25      , 0.375     , 0.25      ,\n",
       "        0.33974359, 0.        ],\n",
       "       [0.66      , 0.75      , 0.75      , 0.75      , 0.875     ,\n",
       "        0.77884615, 1.        ],\n",
       "       [0.3       , 0.46428571, 0.25      , 0.5       , 0.25      ,\n",
       "        0.45833333, 0.        ],\n",
       "       [0.36      , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.46153846, 0.        ],\n",
       "       [0.12      , 0.10714286, 0.25      , 0.5       , 0.25      ,\n",
       "        0.23717949, 1.        ],\n",
       "       [0.78      , 0.75      , 1.        , 1.        , 0.875     ,\n",
       "        0.84935897, 1.        ],\n",
       "       [0.34      , 0.46428571, 0.25      , 0.25      , 0.625     ,\n",
       "        0.41666667, 0.        ],\n",
       "       [0.66      , 0.67857143, 1.        , 0.75      , 1.        ,\n",
       "        0.98076923, 1.        ],\n",
       "       [0.58      , 0.57142857, 0.25      , 0.375     , 0.5       ,\n",
       "        0.62820513, 0.        ],\n",
       "       [0.32      , 0.46428571, 0.25      , 0.5       , 0.375     ,\n",
       "        0.46794872, 0.        ],\n",
       "       [0.7       , 0.5       , 0.5       , 0.625     , 0.75      ,\n",
       "        0.51282051, 1.        ],\n",
       "       [0.72      , 0.78571429, 0.75      , 0.75      , 0.625     ,\n",
       "        0.75641026, 1.        ],\n",
       "       [0.18      , 0.14285714, 0.25      , 0.125     , 0.25      ,\n",
       "        0.33974359, 0.        ],\n",
       "       [0.78      , 0.78571429, 0.25      , 0.25      , 0.75      ,\n",
       "        0.56410256, 1.        ],\n",
       "       [0.82      , 0.82142857, 1.        , 0.75      , 0.625     ,\n",
       "        0.84615385, 1.        ],\n",
       "       [0.7       , 0.71428571, 0.75      , 0.625     , 0.625     ,\n",
       "        0.67948718, 0.        ],\n",
       "       [0.44      , 0.53571429, 0.5       , 0.5       , 0.5       ,\n",
       "        0.53205128, 1.        ],\n",
       "       [0.54      , 0.5       , 0.5       , 0.625     , 0.5       ,\n",
       "        0.34935897, 1.        ],\n",
       "       [0.6       , 0.67857143, 0.75      , 0.875     , 0.625     ,\n",
       "        0.66346154, 1.        ],\n",
       "       [0.96      , 0.82142857, 1.        , 0.875     , 1.        ,\n",
       "        0.77884615, 1.        ],\n",
       "       [0.7       , 0.64285714, 0.25      , 0.5       , 0.375     ,\n",
       "        0.62820513, 1.        ],\n",
       "       [0.64      , 0.53571429, 0.5       , 0.625     , 0.625     ,\n",
       "        0.53205128, 1.        ],\n",
       "       [0.14      , 0.25      , 0.75      , 0.5       , 0.625     ,\n",
       "        0.32371795, 0.        ],\n",
       "       [0.54      , 0.28571429, 0.25      , 0.5       , 0.375     ,\n",
       "        0.56730769, 0.        ],\n",
       "       [0.38      , 0.5       , 0.25      , 0.375     , 0.375     ,\n",
       "        0.38461538, 0.        ],\n",
       "       [0.72      , 0.67857143, 1.        , 0.875     , 0.75      ,\n",
       "        0.77884615, 1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , 0.625     , 0.375     ,\n",
       "        0.34615385, 0.        ],\n",
       "       [0.44      , 0.42857143, 0.5       , 0.625     , 0.625     ,\n",
       "        0.51923077, 0.        ],\n",
       "       [0.74      , 0.75      , 0.5       , 0.625     , 0.5       ,\n",
       "        0.59615385, 1.        ],\n",
       "       [0.18      , 0.28571429, 0.5       , 0.25      , 0.25      ,\n",
       "        0.39102564, 0.        ],\n",
       "       [0.62      , 0.71428571, 0.5       , 0.5       , 0.875     ,\n",
       "        0.68910256, 1.        ],\n",
       "       [0.38      , 0.42857143, 0.25      , 0.25      , 0.375     ,\n",
       "        0.46794872, 0.        ],\n",
       "       [0.24      , 0.25      , 0.        , 0.25      , 0.25      ,\n",
       "        0.14423077, 0.        ],\n",
       "       [0.64      , 0.64285714, 0.5       , 0.5       , 0.625     ,\n",
       "        0.38461538, 0.        ],\n",
       "       [0.46      , 0.39285714, 0.5       , 0.75      , 0.75      ,\n",
       "        0.625     , 0.        ],\n",
       "       [0.68      , 0.60714286, 0.5       , 0.625     , 0.5       ,\n",
       "        0.68589744, 1.        ],\n",
       "       [0.42      , 0.25      , 0.        , 0.375     , 0.5       ,\n",
       "        0.5224359 , 1.        ],\n",
       "       [0.54      , 0.39285714, 0.5       , 0.375     , 0.5       ,\n",
       "        0.55769231, 1.        ],\n",
       "       [0.34      , 0.35714286, 0.5       , 0.5       , 0.5       ,\n",
       "        0.47115385, 0.        ],\n",
       "       [0.92      , 0.96428571, 0.75      , 0.875     , 0.75      ,\n",
       "        0.90384615, 1.        ],\n",
       "       [0.52      , 0.35714286, 0.5       , 0.25      , 0.5       ,\n",
       "        0.19230769, 0.        ],\n",
       "       [0.3       , 0.42857143, 0.25      , 0.375     , 0.125     ,\n",
       "        0.31730769, 0.        ],\n",
       "       [0.38      , 0.28571429, 0.25      , 0.5       , 0.5       ,\n",
       "        0.41666667, 0.        ],\n",
       "       [0.3       , 0.5       , 0.25      , 0.5       , 0.5       ,\n",
       "        0.43589744, 0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adf7cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c71b221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                80        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147 (588.00 Byte)\n",
      "Trainable params: 147 (588.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7148b9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 15ms/step - loss: 0.3262 - val_loss: 0.2307\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1880 - val_loss: 0.1235\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0966 - val_loss: 0.0593\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0447 - val_loss: 0.0272\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0164\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0158\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0160\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0147\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.0136\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0127\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')\n",
    "history=model.fit(X_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65cb7000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5d9f55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7293530681277443"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2f06ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25a7ad5a170>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6UElEQVR4nO3dfXhU5YH//8+Z5wTICAQSkBCjqwLSUgwKwWLrbo1SbbXtb822a7S/arvsagty7balaGvZbaPfbV20K1i6tvzcrpD2QqvtF1djtytQWF1j4vq01bZoEBMxETJ5nszM/ftjZk5mkkBmknkI8H5dnWuSM/ecuc+d2Hy4n45ljDECAACYxBz5rgAAAMBYCCwAAGDSI7AAAIBJj8ACAAAmPQILAACY9AgsAABg0iOwAACASY/AAgAAJj1XviuQKZFIRO+8846mTZsmy7LyXR0AAJACY4y6uro0d+5cORzH70c5ZQLLO++8o7KysnxXAwAAjMOhQ4c0b968475+ygSWadOmSYpecFFRUZ5rAwAAUhEIBFRWVmb/HT+eUyawxIeBioqKCCwAAJxkxprOwaRbAAAw6RFYAADApEdgAQAAkx6BBQAATHoEFgAAMOkRWAAAwKRHYAEAAJMegQUAAEx6BBYAADDpEVgAAMCkR2ABAACTHoEFAABMeqfMzQ+z5cF9B9XS0aPPLS/X+aUnvpMkAADIDnpYxvB//+cd/X8H3tJbHT35rgoAAKctAssYvC6nJKk/FMlzTQAAOH0RWMbgdUebaGAwnOeaAABw+iKwjMHrigUWelgAAMgbAssY4kNCBBYAAPKHwDKGoR4WhoQAAMgXAssYhuaw0MMCAEC+EFjGwJAQAAD5R2AZg8/NkBAAAPlGYBkDPSwAAOQfgWUM9qRb5rAAAJA3BJYxsEoIAID8I7CMweuObc1PDwsAAHlDYBkDPSwAAOQfgWUMTLoFACD/CCxj4F5CAADkH4FlDNytGQCA/COwjCE+JBSkhwUAgLwhsIxhaKdbAgsAAPlCYBnD0KRbhoQAAMgXAssY2OkWAID8I7CMwcuQEAAAeUdgGYM96TYcUThi8lwbAABOTwSWMcSHhCRWCgEAkC/jCixbtmxRRUWFfD6fKisrtXfv3uOW3bdvny655BLNnDlTBQUFWrBggf7pn/5pRLldu3Zp0aJF8nq9WrRokR599NHxVC3jEgMLE28BAMiPtANLfX291q1bp40bN6qpqUmrVq3S6tWr1dLSMmr5KVOm6NZbb9WePXv02muv6fbbb9ftt9+ubdu22WUOHDigmpoa1dbW6sUXX1Rtba2uu+46Pfvss+O/sgxxOR1yOixJzGMBACBfLGNMWhMzli9frgsvvFBbt261jy1cuFDXXnut6urqUjrHpz/9aU2ZMkX/+q//KkmqqalRIBDQE088YZe58sorNX36dO3YsSOlcwYCAfn9fnV2dqqoqCiNKxrbom/+u3qDYe35u8s0f2ZhRs8NAMDpLNW/32n1sASDQTU2Nqq6ujrpeHV1tfbv35/SOZqamrR//3595CMfsY8dOHBgxDmvuOKKE55zYGBAgUAg6ZEt3LEZAID8SiuwtLe3KxwOq6SkJOl4SUmJ2traTvjeefPmyev1atmyZbrlllt0880326+1tbWlfc66ujr5/X77UVZWls6lpIU7NgMAkF/jmnRrWVbS98aYEceG27t3r55//nk98MAD2rx584ihnnTPuWHDBnV2dtqPQ4cOpXkVqRvanp8eFgAA8sGVTuHi4mI5nc4RPR9HjhwZ0UMyXEVFhSTpAx/4gN59913deeed+uxnPytJKi0tTfucXq9XXq83neqPm93Dwm63AADkRVo9LB6PR5WVlWpoaEg63tDQoJUrV6Z8HmOMBgYG7O+rqqpGnPOpp55K65zZxG63AADkV1o9LJK0fv161dbWatmyZaqqqtK2bdvU0tKiNWvWSIoO1Rw+fFgPPfSQJOn+++/X/PnztWDBAknRfVm+973v6ctf/rJ9zrVr1+rSSy/V3XffrWuuuUaPPfaYnn76ae3bty8T1zhhTLoFACC/0g4sNTU16ujo0KZNm9Ta2qrFixdr9+7dKi8vlyS1trYm7ckSiUS0YcMGHTx4UC6XS+ecc47uuusu/dVf/ZVdZuXKldq5c6duv/123XHHHTrnnHNUX1+v5cuXZ+ASJy4+JNTPkBAAAHmR9j4sk1U292G5aft/69f/e0R3f+YDqrlofkbPDQDA6Swr+7CcrpjDAgBAfhFYUsAqIQAA8ovAkgIm3QIAkF8ElhQMBRZ6WAAAyAcCSwq8brbmBwAgnwgsKfDFe1gGGRICACAfCCwpoIcFAID8IrCkgDksAADkF4ElBfHA0s+QEAAAeUFgSYG9Dws9LAAA5AWBJQVDO93SwwIAQD4QWFJgz2Fhp1sAAPKCwJIChoQAAMgvAksK2JofAID8IrCkgLs1AwCQXwSWFHC3ZgAA8ovAkgIfq4QAAMgrAksKmHQLAEB+EVhSkLjTrTEmz7UBAOD0Q2BJQbyHJWKkUITAAgBArhFYUhBfJSQxLAQAQD4QWFLgcSYEFm6ACABAzhFYUuBwWHZooYcFAIDcI7CkaGi3WwILAAC5RmBJEXdsBgAgfwgsKWK3WwAA8ofAkiLuJwQAQP4QWFI0tNstQ0IAAOQagSVF9qRbhoQAAMg5AkuK7O356WEBACDnCCwp8rqZdAsAQL4QWFLEPiwAAOQPgSVFQ4GFISEAAHKNwJKioVVC9LAAAJBrBJYU2fuwMIcFAICcI7CkiCEhAADyh8CSIp+bISEAAPKFwJIielgAAMgfAkuKuPkhAAD5Q2BJ0dBOtwQWAAByjcCSoqFVQgwJAQCQa+MKLFu2bFFFRYV8Pp8qKyu1d+/e45Z95JFHdPnll2vWrFkqKipSVVWVnnzyyaQy27dvl2VZIx79/f3jqV5WsA8LAAD5k3Zgqa+v17p167Rx40Y1NTVp1apVWr16tVpaWkYtv2fPHl1++eXavXu3Ghsbddlll+kTn/iEmpqaksoVFRWptbU16eHz+cZ3VVnApFsAAPLHle4b7rnnHt100026+eabJUmbN2/Wk08+qa1bt6qurm5E+c2bNyd9/93vflePPfaYfvnLX2rp0qX2ccuyVFpamm51coZ7CQEAkD9p9bAEg0E1Njaquro66Xh1dbX279+f0jkikYi6uro0Y8aMpOPd3d0qLy/XvHnzdPXVV4/ogRluYGBAgUAg6ZFN3K0ZAID8SSuwtLe3KxwOq6SkJOl4SUmJ2traUjrH97//ffX09Oi6666zjy1YsEDbt2/X448/rh07dsjn8+mSSy7RG2+8cdzz1NXVye/324+ysrJ0LiVtDAkBAJA/45p0a1lW0vfGmBHHRrNjxw7deeedqq+v1+zZs+3jK1as0PXXX68lS5Zo1apV+tnPfqbzzjtPP/jBD457rg0bNqizs9N+HDp0aDyXkjKGhAAAyJ+05rAUFxfL6XSO6E05cuTIiF6X4err63XTTTfp5z//uT72sY+dsKzD4dBFF110wh4Wr9crr9ebeuUniK35AQDIn7R6WDwejyorK9XQ0JB0vKGhQStXrjzu+3bs2KHPf/7zevjhh3XVVVeN+TnGGDU3N2vOnDnpVC+r7B4W9mEBACDn0l4ltH79etXW1mrZsmWqqqrStm3b1NLSojVr1kiKDtUcPnxYDz30kKRoWLnhhht07733asWKFXbvTEFBgfx+vyTp29/+tlasWKFzzz1XgUBA9913n5qbm3X//fdn6jonzEsPCwAAeZN2YKmpqVFHR4c2bdqk1tZWLV68WLt371Z5ebkkqbW1NWlPlh/+8IcKhUK65ZZbdMstt9jHb7zxRm3fvl2SdOzYMX3pS19SW1ub/H6/li5dqj179ujiiy+e4OVlTuIcllTn7AAAgMywjDEm35XIhEAgIL/fr87OThUVFWX8/F39g/rAnU9Jkv7376+057QAAIDxS/XvN/cSSlF8a36JYSEAAHKNwJIit9NSfBSIvVgAAMgtAkuKLMtKWClEDwsAALlEYEkDd2wGACA/CCxpYHt+AADyg8CSBna7BQAgPwgsaWAOCwAA+UFgSYPXzZAQAAD5QGBJQ3zSbT89LAAA5BSBJQ1MugUAID8ILGlIvJ8QAADInbRvfnja6WmXBgLS1BL2YQEAIE/oYRnLTz8j3bdUenPf0KTbQYaEAADIJQLLWDxTos+DvQwJAQCQJwSWsbgLos/BXoaEAADIEwLLWNyF0eekHhaGhAAAyCUCy1jswNI3tDU/+7AAAJBTBJaxxIeEmMMCAEDeEFjGkjjplq35AQDICwLLWEabdMuQEAAAOUVgGUvCHBYm3QIAkB8ElrHYgaUnYUiIHhYAAHKJwDIWT2IPC0NCAADkA4FlLOzDAgBA3hFYxhIPLOx0CwBA3hBYxmLvw9LHHBYAAPKEwDKWhEm3PnsOC0NCAADkEoFlLImTbulhAQAgLwgsY0maw0JgAQAgHwgsY0lcJeSMNlc/Q0IAAOQUgWUs8Um3JiyvIxpUQhGjUJheFgAAcoXAMpb4zQ8leU2//XWQwAIAQM4QWMbidEsOlyTJExkKLOx2CwBA7hBYUhGbx+IK98vlsCQx8RYAgFwisKSC7fkBAMgrAksq7N1ue+V1sz0/AAC5RmBJRXzibWIPC3NYAADIGQJLKuI9LMFe+eweFoaEAADIFQJLKtwJ2/Oz2y0AADlHYEkFk24BAMgrAksqEifdxu7Y3M8cFgAAcmZcgWXLli2qqKiQz+dTZWWl9u7de9yyjzzyiC6//HLNmjVLRUVFqqqq0pNPPjmi3K5du7Ro0SJ5vV4tWrRIjz766Hiqlh2ehB4WNz0sAADkWtqBpb6+XuvWrdPGjRvV1NSkVatWafXq1WppaRm1/J49e3T55Zdr9+7damxs1GWXXaZPfOITampqssscOHBANTU1qq2t1Ysvvqja2lpdd911evbZZ8d/ZZk02h2b6WEBACBnLGOMSecNy5cv14UXXqitW7faxxYuXKhrr71WdXV1KZ3jggsuUE1Njb75zW9KkmpqahQIBPTEE0/YZa688kpNnz5dO3bsSOmcgUBAfr9fnZ2dKioqSuOKUtDwLem3m6UVt+iWjv9H//elVn37kxfoxpVnZfZzAAA4zaT69zutHpZgMKjGxkZVV1cnHa+urtb+/ftTOkckElFXV5dmzJhhHztw4MCIc15xxRUnPOfAwIACgUDSI2vsSbc9TLoFACAP0gos7e3tCofDKikpSTpeUlKitra2lM7x/e9/Xz09PbruuuvsY21tbWmfs66uTn6/336UlZWlcSVp8iQsa3YzJAQAQK6Na9KtZVlJ3xtjRhwbzY4dO3TnnXeqvr5es2fPntA5N2zYoM7OTvtx6NChNK4gTaOsEmIfFgAAcseVTuHi4mI5nc4RPR9HjhwZ0UMyXH19vW666Sb9/Oc/18c+9rGk10pLS9M+p9frldfrTaf645c46baIISEAAHItrR4Wj8ejyspKNTQ0JB1vaGjQypUrj/u+HTt26POf/7wefvhhXXXVVSNer6qqGnHOp5566oTnzKmknW7pYQEAINfS6mGRpPXr16u2tlbLli1TVVWVtm3bppaWFq1Zs0ZSdKjm8OHDeuihhyRFw8oNN9yge++9VytWrLB7UgoKCuT3+yVJa9eu1aWXXqq7775b11xzjR577DE9/fTT2rdvX6auc2JGm3TLHBYAAHIm7TksNTU12rx5szZt2qQPfehD2rNnj3bv3q3y8nJJUmtra9KeLD/84Q8VCoV0yy23aM6cOfZj7dq1dpmVK1dq586d+slPfqIPfvCD2r59u+rr67V8+fIMXGIGeEbeS6ifISEAAHIm7X1YJqus7sNyuFH60Z9KRfP0ryt3645fvKwrLyjVA7WVmf0cAABOM1nZh+W05Z4SfebmhwAA5AWBJRVJy5rjgYU5LAAA5AqBJRWeWA9LqF9eZ3RvGAILAAC5Q2BJRbyHRVKBIyiJISEAAHKJwJIK11BgKTT9kljWDABALhFYUuFw2KGlwIr2sPQN0sMCAECuEFhSFRsWmhIPLEECCwAAuUJgSVVs4m1hLLD0BEP5rA0AAKcVAkuqYj0sBRqQJPUPRhSOnBJ77gEAMOkRWFIVu5+QLxZYJHpZAADIFQJLqmKBxR3pl8sR3Yuld4B5LAAA5AKBJVWxISFrsFeFHqckelgAAMgVAkuq7Ds292qK1yWJHhYAAHKFwJKq2JCQgkM9LN0D9LAAAJALBJZUxQPLYJ+mxntYGBICACAnCCypsgNLjwo90cDSw+ZxAADkBIElVZ6hHpYp3uiQUC9DQgAA5ASBJVXxOzYP9to9LMxhAQAgNwgsqUqYdGuvEmJICACAnCCwpCph0u0U9mEBACCnCCypSpx0yz4sAADkFIElVZ5ReliYwwIAQE4QWFIVn3Qb7LV7WBgSAgAgNwgsqXJPiT4P9mpqfFkzk24BAMgJAkuqRlnWzJAQAAC5QWBJVdIqoXhgoYcFAIBcILCkKuFuzYVeljUDAJBLBJZUxYeEIiFNdUUkMYcFAIBcIbCkKj7pVtIUR1ASc1gAAMgVAkuqnG7Jig4FTVE0sAyEIgqFI/msFQAApwUCS6osS/JEe1kKHQP24R6GhQAAyDoCSzpi81g84X65nZYkqZeJtwAAZB2BJR0JS5sLWdoMAEDOEFjS4R5a2sz9hAAAyB0CSzoSd7vlfkIAAOQMgSUdiXdsjgWWXoaEAADIOgJLOuJDQsGeoSEhelgAAMg6Aks6mHQLAEBeEFjSYQeWHk2J3U+IZc0AAGQfgSUdo8xhoYcFAIDsI7CkI75KKDi0rJkeFgAAsm9cgWXLli2qqKiQz+dTZWWl9u7de9yyra2t+tznPqfzzz9fDodD69atG1Fm+/btsixrxKO/v3881cuehH1Y4nNYutmHBQCArEs7sNTX12vdunXauHGjmpqatGrVKq1evVotLS2jlh8YGNCsWbO0ceNGLVmy5LjnLSoqUmtra9LD5/OlW73scicOCcV7WBgSAgAg29IOLPfcc49uuukm3XzzzVq4cKE2b96ssrIybd26ddTyZ511lu69917dcMMN8vv9xz2vZVkqLS1Nekw69sZxPQlzWOhhAQAg29IKLMFgUI2Njaqurk46Xl1drf3790+oIt3d3SovL9e8efN09dVXq6mp6YTlBwYGFAgEkh5ZF7tbswb7NCU2JEQPCwAA2ZdWYGlvb1c4HFZJSUnS8ZKSErW1tY27EgsWLND27dv1+OOPa8eOHfL5fLrkkkv0xhtvHPc9dXV18vv99qOsrGzcn5+yhEm3hbFJt8xhAQAg+8Y16dayrKTvjTEjjqVjxYoVuv7667VkyRKtWrVKP/vZz3TeeefpBz/4wXHfs2HDBnV2dtqPQ4cOjfvzU+aO97D0Dm3NzyohAACyzpVO4eLiYjmdzhG9KUeOHBnR6zIRDodDF1100Ql7WLxer7xeb8Y+MyUJNz9kHxYAAHInrR4Wj8ejyspKNTQ0JB1vaGjQypUrM1YpY4yam5s1Z86cjJ0zIxJXCbEPCwAAOZNWD4skrV+/XrW1tVq2bJmqqqq0bds2tbS0aM2aNZKiQzWHDx/WQw89ZL+nublZUnRi7Xvvvafm5mZ5PB4tWrRIkvTtb39bK1as0LnnnqtAIKD77rtPzc3Nuv/++zNwiRnkSdiHhR4WAAByJu3AUlNTo46ODm3atEmtra1avHixdu/erfLycknRjeKG78mydOlS++vGxkY9/PDDKi8v15tvvilJOnbsmL70pS+pra1Nfr9fS5cu1Z49e3TxxRdP4NKyYJSdboPhiIKhiDwuNg0GACBbLGOMyXclMiEQCMjv96uzs1NFRUXZ+ZDu96Tv/YkkKbixQ+fd8aQk6cVvVstf6M7OZwIAcApL9e833QLpiPewSPKYAXmc0ebrYR4LAABZRWBJR3zSrSQN9qkwtj0/u90CAJBdBJZ0OBySK3Z/o2CPvdttD7vdAgCQVQSWdNl7sfTZu9320sMCAEBWEVjSNcput/SwAACQXQSWdCXtdsscFgAAcoHAki7P0G63hfYcFgILAADZRGBJV3ylULBnaHt+drsFACCrCCzpSryfkJceFgAAcoHAki57DktPwh2bCSwAAGQTgSVdnvgqoaFlzawSAgAguwgs6Uq6AWK0h4V9WAAAyC4CS7rsOSzswwIAQK4QWNKVNOmWfVgAAMgFAku6EibdFnIvIQAAcoLAkq6ESbdTuJcQAAA5QWBJV+Kk29gcll56WAAAyCoCS7qSbn4Y7WHppocFAICsIrCkK+Hmh/E5LL3sdAsAQFYRWNJlB5Y+ex+WwbBRMBTJY6UAADi1EVjSFZ90G+xRYWxISKKXBQCAbCKwpMvnjz73d8rtdMjjijYh81gAAMgeAku6fGdEn/uPSZHI0NJmVgoBAJA1BJZ0FZwRfTYRKdg1tHkcPSwAAGQNgSVd7gLJ5Yt+3XdMU9mLBQCArCOwjEd8WKjvqD3xljksAABkD4FlPAqmR5/7j9lLm1klBABA9hBYxiM+j6XvqAo98Ts2MyQEAEC2EFjGI97D0ncs4X5C9LAAAJAtBJbxSFjaPHQ/IXpYAADIFgLLeCQMCdlzWJh0CwBA1hBYxiNhSMjeh4VlzQAAZA2BZTwSljXHh4SYwwIAQPYQWMYjcVmzl51uAQDINgLLeLCsGQCAnCKwjIc9h6WTjeMAAMgBAst4JCxrjm/Nz6RbAACyh8AyHvEhoYGAprqjXzKHBQCA7CGwjEe8h0XSVNMricACAEA2EVjGw+mSPNMkSVNNQJLUGwzLGJPPWgEAcMoisIxXbOJtYbhbkhSKGAXDkXzWCACAU9a4AsuWLVtUUVEhn8+nyspK7d2797hlW1tb9bnPfU7nn3++HA6H1q1bN2q5Xbt2adGiRfJ6vVq0aJEeffTR8VQtdwr80adQp32ol6XNAABkRdqBpb6+XuvWrdPGjRvV1NSkVatWafXq1WppaRm1/MDAgGbNmqWNGzdqyZIlo5Y5cOCAampqVFtbqxdffFG1tbW67rrr9Oyzz6ZbvdyJ9bA4BwLyuqLN2M08FgAAssIyaU68WL58uS688EJt3brVPrZw4UJde+21qqurO+F7P/rRj+pDH/qQNm/enHS8pqZGgUBATzzxhH3syiuv1PTp07Vjx46U6hUIBOT3+9XZ2amioqLUL2i86mul1x6XPv49XfjkWXq/J6gn112q80unZf+zAQA4RaT69zutHpZgMKjGxkZVV1cnHa+urtb+/fvHV1NFe1iGn/OKK6444TkHBgYUCASSHjk12m63bB4HAEBWpBVY2tvbFQ6HVVJSknS8pKREbW1t465EW1tb2uesq6uT3++3H2VlZeP+/HFJuGPz1Nj9hJjDAgBAdoxr0q1lWUnfG2NGHMv2OTds2KDOzk77cejQoQl9ftoS7tgc72FhDgsAANnhSqdwcXGxnE7niJ6PI0eOjOghSUdpaWna5/R6vfJ6veP+zAkb5Y7N3E8IAIDsSKuHxePxqLKyUg0NDUnHGxoatHLlynFXoqqqasQ5n3rqqQmdM+tGmcNCDwsAANmRVg+LJK1fv161tbVatmyZqqqqtG3bNrW0tGjNmjWSokM1hw8f1kMPPWS/p7m5WZLU3d2t9957T83NzfJ4PFq0aJEkae3atbr00kt1991365prrtFjjz2mp59+Wvv27cvAJWZJwhyW6X6PJOloz2AeKwQAwKkr7cBSU1Ojjo4Obdq0Sa2trVq8eLF2796t8vJySdGN4obvybJ06VL768bGRj388MMqLy/Xm2++KUlauXKldu7cqdtvv1133HGHzjnnHNXX12v58uUTuLQsS7hj88yp0cDyfs9A/uoDAMApLO19WCarnO/DcvRN6d4lksunH3/0v7TpV6/qqg/O0f2fuzD7nw0AwCkiK/uwIEF8SCjUr1kF0XsIdXTTwwIAQDYQWMbLM02yos1X4uqXJL3fE8xnjQAAOGURWMbL4bDnscx09kqSOroJLAAAZAOBZSJiS5tnOHokSUd7gwpHTokpQQAATCoElomIzWOZpm5JUsRIx3rpZQEAINMILBMRGxJyBQPyF7glMY8FAIBsILBMRMJut/G9WNqZxwIAQMYRWCYiYbfbmVPim8cRWAAAyDQCy0Qk3LF55pTojRg72O0WAICMI7BMRMIdm2cwJAQAQNYQWCbCnsNyTMVTuJ8QAADZQmCZiMQhoamxISF6WAAAyDgCy0QkDgnFelg6mHQLAEDGEVgmYpRlzdwAEQCAzCOwTETisuZCljUDAJAtBJaJiM9hMWEVe6JB5WjvoELhSP7qBADAKYjAMhHuAskZnWx7htUjy4oePto7mMdKAQBw6iGwTIRl2fNYnAOdml4Yn3jLPBYAADKJwDJRSbvdxifeMo8FAIBMIrBMFEubAQDIOgLLRCUsbS62N49jSAgAgEwisExUwtLmGdyxGQCArCCwTFTS9vzcABEAgGwgsExUwhyWmdwAEQCArCCwTFTCHZu5ASIAANlBYJmoUZY1M4cFAIDMIrBMVOKQkD2HhSEhAAAyicAyUYl3bJ4SHRIK9IcUDHE/IQAAMoXAMlH2suZO+QvccjqiNxQ62suwEAAAmUJgmaj4HJaBTjkUse8nxLAQAACZQ2CZqPiQkCT1d6p4KhNvAQDINALLRDndkmdq9Ou+o0P3E2JpMwAAGUNgyQR7aXPCXiz0sAAAkDEElkywlzYP7cXCDRABAMgcAksmJO52y+ZxAABkHIElE+KBpbdDM7gBIgAAGUdgyQT//OjzsRZ787gOboAIAEDGEFgyYUZF9Pn9gyxrBgAgCwgsmTA9FliOHmRZMwAAWUBgyYR4D8vRN+1Jt90DIfUPhvNYKQAATh0Elkzwl0mWQxrsVVGoQ25n9H5CDAsBAJAZ4wosW7ZsUUVFhXw+nyorK7V3794Tln/mmWdUWVkpn8+ns88+Ww888EDS69u3b5dlWSMe/f3946le7rk8kn+eJMk6+qY9LERgAQAgM9IOLPX19Vq3bp02btyopqYmrVq1SqtXr1ZLS8uo5Q8ePKiPf/zjWrVqlZqamvSNb3xDX/nKV7Rr166kckVFRWptbU16+Hy+8V1VPiTNY4muFOIGiAAAZEbageWee+7RTTfdpJtvvlkLFy7U5s2bVVZWpq1bt45a/oEHHtD8+fO1efNmLVy4UDfffLO+8IUv6Hvf+15SOcuyVFpamvQ4qbBSCACArEkrsASDQTU2Nqq6ujrpeHV1tfbv3z/qew4cODCi/BVXXKHnn39eg4OD9rHu7m6Vl5dr3rx5uvrqq9XU1HTCugwMDCgQCCQ98iqhh2UmK4UAAMiotAJLe3u7wuGwSkpKko6XlJSora1t1Pe0tbWNWj4UCqm9vV2StGDBAm3fvl2PP/64duzYIZ/Pp0suuURvvPHGcetSV1cnv99vP8rKytK5lMxL6GGxh4TYPA4AgIwY16Rby7KSvjfGjDg2VvnE4ytWrND111+vJUuWaNWqVfrZz36m8847Tz/4wQ+Oe84NGzaos7PTfhw6dGg8l5I5iT0s8SEhelgAAMgIVzqFi4uL5XQ6R/SmHDlyZEQvSlxpaemo5V0ul2bOnDnqexwOhy666KIT9rB4vV55vd50qp9d8R6W3g6VeKJBpYM5LAAAZERaPSwej0eVlZVqaGhIOt7Q0KCVK1eO+p6qqqoR5Z966iktW7ZMbrd71PcYY9Tc3Kw5c+akU7388k6TCoslSfP0riQCCwAAmZL2kND69ev1L//yL/rxj3+s1157TbfddptaWlq0Zs0aSdGhmhtuuMEuv2bNGr311ltav369XnvtNf34xz/Wgw8+qL/927+1y3z729/Wk08+qT/+8Y9qbm7WTTfdpObmZvucJ43pZ0mSZoXekSR1sKwZAICMSGtISJJqamrU0dGhTZs2qbW1VYsXL9bu3btVXl4uSWptbU3ak6WiokK7d+/Wbbfdpvvvv19z587Vfffdp8985jN2mWPHjulLX/qS2tra5Pf7tXTpUu3Zs0cXX3xxBi4xh2ZUSIef14yBtyWdofbugTHn9wAAgLFZJj4D9iQXCATk9/vV2dmpoqKi/FTiP74j7fk/Ci+9UQufW61gOKK9X71MZTMK81MfAAAmuVT/fnMvoUyKTbx1Hjuoc0umSpJeeSfP+8MAAHAKILBkUnxp8/tvauGcaEp8rZXAAgDARBFYMim+tDnwthaXFEiSXiWwAAAwYQSWTJpaIrkLJRPRkmmdkuhhAQAgEwgsmWRZ9tLm89zR2w68fbRPnX2DJ3gTAAAYC4El02LzWKb0vq0zz4gOC/0vvSwAAEwIgSXTEm6CGJ94yzwWAAAmhsCSabEhIR09qEVzpkliHgsAABNFYMm0hB6WRXPpYQEAIBMILJkW34vl6JtaWBrtYXm9rVuD4UgeKwUAwMmNwJJpZ8yXLKcU6lOZO6CpXpeC4Yj++F5PvmsGAMBJi8CSaU635J8nSXIce1MLYr0sr7Z25rNWAACc1Ags2TDKPJbXWrvyWCEAAE5uBJZssOexJCxt5iaIAACMG4ElGxJ7WBJugmiMyWOlAAA4eRFYsiGhh+X80mlyWFJHT1BHugbyWy8AAE5SBJZsiPewdPxBPqels2dNlcR+LAAAjBeBJRtmniv5/FL/MemP/8E8FgAAJojAkg1un/TBv4h+/fxP7Hks9LAAADA+BJZsWfb/Rp9/94SW+HslcU8hAADGi8CSLbMXSmUrJBPWB9t/JUk62N6j3mAozxUDAODkQ2DJplgvy9SXH9bsKS4ZI/2ujQ3kAABIF4ElmxZdI/nOkDpb9OfTX5ckvcLEWwAA0kZgySZ3gbTks5KkT0UaJEkPHXhTwRB3bgYAIB0ElmyLDQudc3Sfzi/s0uvvduvBfQfzXCkAAE4uBJZsm3W+NH+lLBPWPee+JEm699ev69D7vXmuGAAAJw8CSy7EelkWtf5CVRV+9Q9G9M3HXubeQgAApMiV7wqcFhZ+Uir4qqzA2/rRzH/Wg+4p+sMbJfqvPe+ratHZUrBLGuiWBrqkUL80d6k085x81xoAgEnDMqfIP/MDgYD8fr86OztVVFSU7+qM1PBN6bf3pl5+5rnSeVdI510pzV8hOd3ZqxsAAHmS6t9vAkuuhAak15+UOt5QqP0PevmlZpWG35HfGZTlK5LxTJPlnSaX05KrrVmKJGww55kmlV0sza+SyqukMyujK5AAADjJpfr3myGhXHF5pUWfjH4pqfOC93Ttj5+LvjZs/u38wkFde8br+qj1ghZ1/5d8waPSH34dfUiSwy3N/ZBUtjwaZMqWS9NKc3YpAADkGj0sefQve/+oZ15/T0d7gzraM6hjvUH1BMNJZRyK6HzrkFY4f6c/LfyDlkReVVGoY+TJ/GVS6QekkgukksXRx4wKyeHM0dUAAJA+hoROUn3BsP7wXrdefze6Z8sb73bp5Xc69W5gIFbCaL51RBdab+hi5+ta4f69zoq8JYdG+TE6vVLxuVLxedKsBdKs86QZ50gzzpa8U3N6XQAAjIbAcgoxxuidzn698NZRvdByVM2Hjul3bV3qjfXGTFWvFjve1AKrRQusFi1yHNJ5jkPyKXj8k04tja5Emn6WVHSm5J8n+c+UiuZJZ5RJnim5uTgAwGmNwHKKi0SMDh/rs3tiXn+3S78/0q3fH+lW32BYDkU0z3pPf2Idjj3e0Z84Dussq00zrO4xz28KZso6o0w6Y3400EydJU2ZLU2dLU2ZJU2bE312Mg0KADB+BJbTVDzIvHGkSy0dvTp0tE+H3u/V20f79PbRXgX6QypStyqsNp1ltWme1a65VofmWB2aa3VortWuIqsvpc8ylkPhgllS0Rw5i0plTSuN9txMnR2dBFxYLBVMlwpnRJ+ZTwMAGIZVQqcph8NS2YxClc0oHPX13mBI7wYG1NbZr3cD/WoL9Ov3gX79NtBvHx/ofl+zwkd0ptWuedZ7KrGOqlidKraij1lWp4rVKZcicvW+K/W+K7WNXbegu0ihgmJFCovlmDpbrqLZck+dKatghlRwRjTU+M6QvNOSH+xBAwCnPQLLaabQ41JFsUsVxcefo2KMUfdASO3dQbV3D6i9a0Dt3QNqjn/fPaBj3X0Kd70nZ++7mhp8T6XWUc2yjmm2jmmW1alZ1lHNUJfOsLrtHhvPYECewYAU+GNadR50+BT0+BXynKGwb7qM7wxZviI5fEVyFBTJVeCXu2CK3G5fdPm40yO5fNGw4/MPPTxTJQd3owCAkxGBBSNYlqVpPrem+dwnDDZxwVBEx3qDOtY3qKM90eff9QbV2TeoY72DCvT2abDrfUV63pPV2yF3X4e8wQ6dYY7pDPXoDKtbfvXIH3ueavVrqvpUYEUnDbsj/XL390v970qBiV1byHIrZHkUdngUdvoUdnoVdhbIuAoUcRVILq8sl0eW0y2H0y3L5ZHD7ZXDXSiHp0BOj08OT6Fcbo8cLq8slzfaA+R0R/fHcXqi83oc8WOuhNfc0WExh2voYTmGHg6nZDmHygEAbAQWTJjH5dDsIp9mF/nSel9fMKxA/6C6+gfV1R9SoD+kt+Nf9w2qq69PA92dMn2dMn1H5eo/KvfgMbmDnfKEeuQJ98gX6VWh6VGBgvJoMPqwQvJqUFPVpyKrV0XqkdeK7hzsMoNymUEp0iOFxqhgHhlZClsuRSyXjOWMPRwylkvG4ZCxnJLlGPaaQ7K/dsqyLFmWI/ZsyXK4ZFweGWe0F8o4PbISA5NlSZZDDsuSwxF9thyOhJAVC2AOpxyx45blkOWIfoYsR/R8suzPlGVJGvYcK6PhryceT3p2jPJ6jP31KO+LtWRC4dE/Z7jh5xxRR0nGRM99vCmAiXVM+oxh77GDqmPYuYefa9jnDy+XVMaSIpHobtmRQSk8KJlI7OfoHgrY1vBQHKubMdHyJhI9ZjmjPZOWcyhIH+/6R/w8Er+2RrbN8PMk/cwdCXWKDH2d9DvrGDrfaD8La5Sf73Aj2lFDbW0i0bY0EcmEo89WQlvEf3YjrjPehvG6a+gfJPFnM+y8xtj/fdn/mElqo8jodT2u4f9NjNE2iedO+nkoua3dhXn7BxWBBXlT4HGqwONUSZpBZ7hQOKLewbB6BkLq7g+peyCkroGw3hsMayAU0UAorGB/n8L9AQ0G+xUe6FVooE/hwT6ZYJ802CdrsFdWqE9WqF8mEpLCQSkckiJBOcNBuUxQ7siAPCYorxWUWyF5FI49D8plheWOfe9KeE487lRYTkXkUkROheWyIse9JksmGqzM4ITaBgAy6d0//6VKLrg0L589rsCyZcsW/eM//qNaW1t1wQUXaPPmzVq1atVxyz/zzDNav369XnnlFc2dO1df/epXtWbNmqQyu3bt0h133KE//OEPOuecc/Sd73xHn/rUp8ZTPZxmXE6HipwOFfnckj+7nxWOGAVDEQVDEQ2Ew/bXg2GjUCSiUNhoIGI0GI5oMBwrZ5eJKBQx0Uc4olAoIksRGROWw0QkRRQJhxQeDCo0OKhwKKjQ4IAUCSkcDsuEw4pEQlI4LBMJR/9lFgnH3h9dym6ZSOw5rHDYKBQJKxyOKBSOyDKhaA9TZFAuDcoZGVS0Lyciy0SfZYxMJKKIMTImetxhReSyw1b02aGIHDKxR0SWjCxFd2a2rGjgUuxY9LXhX0ffm/S+WG/IyLJDrzs1FPLsf79bJum98WcTKxF/TvzM+PNI8fcP//yheg+9y7LPPZqh85v4v7kTzhr/jEisPaPtmHg+I2tYm0TrnVwmua6OWFtEjEODsYgcjcoOOZUQqq3wqNcfkUPGWAk/UUXrZ0Xr6YzVMf7TTbyW5Ksbqtfwdo2XG/r5JL4y9LOJf1a8LhEN9V4M/90btacsyWg/65HtGP9ZxX+/I7IUjn0X/a/VIUfCz8xp1y7xt83Eahdrz9hnxP+7cSoip2UUMfFzR8+r2Oe6FJbTGuVnY4ZaM15zR+w8wzlGeX+mHO0LqSRrZz+xtANLfX291q1bpy1btuiSSy7RD3/4Q61evVqvvvqq5s+fP6L8wYMH9fGPf1xf/OIX9dOf/lS//e1v9Td/8zeaNWuWPvOZz0iSDhw4oJqaGv393/+9PvWpT+nRRx/Vddddp3379mn58uUTv0ogQ5wOy+4Zkk791UuRSPT/+Iyik7ElKWKkiDGKGKNwxER7zGXsXuR42ehz9LXY/6LlTfQ9EbvMUFnFzmMUe93EeudlxZ6jho8qRIwUikQUicSeR/3/6+j5IpLCZuj88fqN9h4z7A/d8GuMfy0zVH60nnU7WFhD1xMvH2+LE9U5sS3jbaGkc1qxr6PP8bnlloYaLRKJ/rzCEaPBYR82bNBKibtdxD83Plo06vVr2AlGXsWo7TGc3TaW7OtJvs6EUatYHZLqp8Sfa/QD42032qhI9FyJv+PJ12e3Z7yNrYQyZvhvx9A5nQ7Lfo/TYckYKWyM/TOIHGcocahcRCYSkmU57Pgev4DjjeSY2O9Q0qmNkUkK+cYuO+ookeKfFy8dif7DJRJ9Niaivzj7T0atey6kvQ/L8uXLdeGFF2rr1q32sYULF+raa69VXV3diPJf+9rX9Pjjj+u1116zj61Zs0YvvviiDhw4IEmqqalRIBDQE088YZe58sorNX36dO3YsSOlerEPCwAAJ59U/36ntcYzGAyqsbFR1dXVScerq6u1f//+Ud9z4MCBEeWvuOIKPf/88xocHDxhmeOdU5IGBgYUCASSHgAA4NSUVmBpb29XOBxWSUnyCFZJSYna2kbfOaytrW3U8qFQSO3t7Scsc7xzSlJdXZ38fr/9KCsrS+dSAADASWRcu2hZwwa/4mN96ZQffjzdc27YsEGdnZ3249ChQynXHwAAnFzSmnRbXFwsp9M5oufjyJEjI3pI4kpLS0ct73K5NHPmzBOWOd45Jcnr9crr9aZTfQAAcJJKq4fF4/GosrJSDQ0NSccbGhq0cuXKUd9TVVU1ovxTTz2lZcuWye12n7DM8c4JAABOL2kva16/fr1qa2u1bNkyVVVVadu2bWppabH3VdmwYYMOHz6shx56SFJ0RdA///M/a/369friF7+oAwcO6MEHH0xa/bN27Vpdeumluvvuu3XNNdfoscce09NPP619+/Zl6DIBAMDJLO3AUlNTo46ODm3atEmtra1avHixdu/erfLycklSa2urWlpa7PIVFRXavXu3brvtNt1///2aO3eu7rvvPnsPFklauXKldu7cqdtvv1133HGHzjnnHNXX17MHCwAAkDSOfVgmK/ZhAQDg5JOVfVgAAADygcACAAAmPQILAACY9AgsAABg0iOwAACASS/tZc2TVXyxEzdBBADg5BH/uz3WouVTJrB0dXVJEjdBBADgJNTV1SW/33/c10+ZfVgikYjeeecdTZs27YQ3TUxXIBBQWVmZDh06xP4uWUZb5w5tnVu0d+7Q1rmTqbY2xqirq0tz586Vw3H8mSqnTA+Lw+HQvHnzsnb+oqIifvlzhLbOHdo6t2jv3KGtcycTbX2inpU4Jt0CAIBJj8ACAAAmPQLLGLxer771rW/J6/XmuyqnPNo6d2jr3KK9c4e2zp1ct/UpM+kWAACcuuhhAQAAkx6BBQAATHoEFgAAMOkRWAAAwKRHYBnDli1bVFFRIZ/Pp8rKSu3duzffVTqp1dXV6aKLLtK0adM0e/ZsXXvttfrd736XVMYYozvvvFNz585VQUGBPvrRj+qVV17JU41PHXV1dbIsS+vWrbOP0daZdfjwYV1//fWaOXOmCgsL9aEPfUiNjY3267R3ZoRCId1+++2qqKhQQUGBzj77bG3atEmRSMQuQ1uPz549e/SJT3xCc+fOlWVZ+sUvfpH0eirtOjAwoC9/+csqLi7WlClT9MlPflJvv/32xCtncFw7d+40brfb/OhHPzKvvvqqWbt2rZkyZYp566238l21k9YVV1xhfvKTn5iXX37ZNDc3m6uuusrMnz/fdHd322XuuusuM23aNLNr1y7z0ksvmZqaGjNnzhwTCATyWPOT23PPPWfOOuss88EPftCsXbvWPk5bZ877779vysvLzec//3nz7LPPmoMHD5qnn37a/P73v7fL0N6Z8Q//8A9m5syZ5le/+pU5ePCg+fnPf26mTp1qNm/ebJehrcdn9+7dZuPGjWbXrl1Gknn00UeTXk+lXdesWWPOPPNM09DQYF544QVz2WWXmSVLlphQKDShuhFYTuDiiy82a9asSTq2YMEC8/Wvfz1PNTr1HDlyxEgyzzzzjDHGmEgkYkpLS81dd91ll+nv7zd+v9888MAD+armSa2rq8uce+65pqGhwXzkIx+xAwttnVlf+9rXzIc//OHjvk57Z85VV11lvvCFLyQd+/SnP22uv/56YwxtnSnDA0sq7Xrs2DHjdrvNzp077TKHDx82DofD/Pu///uE6sOQ0HEEg0E1Njaquro66Xh1dbX279+fp1qdejo7OyVJM2bMkCQdPHhQbW1tSe3u9Xr1kY98hHYfp1tuuUVXXXWVPvaxjyUdp60z6/HHH9eyZcv053/+55o9e7aWLl2qH/3oR/brtHfmfPjDH9avf/1rvf7665KkF198Ufv27dPHP/5xSbR1tqTSro2NjRocHEwqM3fuXC1evHjCbX/K3Pww09rb2xUOh1VSUpJ0vKSkRG1tbXmq1anFGKP169frwx/+sBYvXixJdtuO1u5vvfVWzut4stu5c6deeOEF/fd///eI12jrzPrjH/+orVu3av369frGN76h5557Tl/5ylfk9Xp1ww030N4Z9LWvfU2dnZ1asGCBnE6nwuGwvvOd7+izn/2sJH63syWVdm1ra5PH49H06dNHlJno304Cyxgsy0r63hgz4hjG59Zbb9X//M//aN++fSNeo90n7tChQ1q7dq2eeuop+Xy+45ajrTMjEolo2bJl+u53vytJWrp0qV555RVt3bpVN9xwg12O9p64+vp6/fSnP9XDDz+sCy64QM3NzVq3bp3mzp2rG2+80S5HW2fHeNo1E23PkNBxFBcXy+l0jkiER44cGZEukb4vf/nLevzxx/Wb3/xG8+bNs4+XlpZKEu2eAY2NjTpy5IgqKyvlcrnkcrn0zDPP6L777pPL5bLbk7bOjDlz5mjRokVJxxYuXKiWlhZJ/G5n0t/93d/p61//uv7iL/5CH/jAB1RbW6vbbrtNdXV1kmjrbEmlXUtLSxUMBnX06NHjlhkvAstxeDweVVZWqqGhIel4Q0ODVq5cmadanfyMMbr11lv1yCOP6D/+4z9UUVGR9HpFRYVKS0uT2j0YDOqZZ56h3dP0Z3/2Z3rppZfU3NxsP5YtW6a//Mu/VHNzs84++2zaOoMuueSSEUv0X3/9dZWXl0vidzuTent75XAk//lyOp32smbaOjtSadfKykq53e6kMq2trXr55Zcn3vYTmrJ7iosva37wwQfNq6++atatW2emTJli3nzzzXxX7aT113/918bv95v//M//NK2trfajt7fXLnPXXXcZv99vHnnkEfPSSy+Zz372syxHzJDEVULG0NaZ9NxzzxmXy2W+853vmDfeeMP827/9myksLDQ//elP7TK0d2bceOON5swzz7SXNT/yyCOmuLjYfPWrX7XL0Nbj09XVZZqamkxTU5ORZO655x7T1NRkb+eRSruuWbPGzJs3zzz99NPmhRdeMH/6p3/KsuZcuP/++015ebnxeDzmwgsvtJffYnwkjfr4yU9+YpeJRCLmW9/6liktLTVer9dceuml5qWXXspfpU8hwwMLbZ1Zv/zlL83ixYuN1+s1CxYsMNu2bUt6nfbOjEAgYNauXWvmz59vfD6fOfvss83GjRvNwMCAXYa2Hp/f/OY3o/5/9I033miMSa1d+/r6zK233mpmzJhhCgoKzNVXX21aWlomXDfLGGMm1kcDAACQXcxhAQAAkx6BBQAATHoEFgAAMOkRWAAAwKRHYAEAAJMegQUAAEx6BBYAADDpEVgAAMCkR2ABAACTHoEFAABMegQWAAAw6RFYAADApPf/A8aAKLvjAFvnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b0b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
